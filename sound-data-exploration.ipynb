{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = \"data/esc50.csv\"  # path of csv file\n",
    "DATA_PATH = \"data/audio/44100/\" # path to folder containing audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv file\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_selection = [\n",
    "    \"thunderstorm\",\n",
    "    \"rain\",\n",
    "    \"sea_weaves\",\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"chirping_birds\",    \n",
    "    \"breathing\",\n",
    "    \"keyboard_typing\",\n",
    "    \"coughing\",\n",
    "    \"drinking_sipping\",\n",
    "    \"car_horn\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = df[df[\"category\"].isin(class_selection)]\n",
    "classes = df_sel['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {i:x for x,i in enumerate(classes)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel.loc[:, 'target'] = df_sel['category'].map(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering and data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a sample \n",
    "sample_df = df_sel.drop_duplicates(subset=['target'])\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing mel spectrograms\n",
    "\n",
    "signals = {}\n",
    "mel_spectrograms = {}\n",
    "mfccs = {}\n",
    "\n",
    "for i, row in tqdm(sample_df.iterrows()):  # every row will be like [[index], [filename , target , category]]\n",
    "    signal , rate = librosa.load(DATA_PATH+ row[\"filename\"])\n",
    "    signals[row[\"category\"]] = signal    # fill signal for each category. eg. signal[\"dog\"] = signal of dog sound\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal , sr=rate ,  n_fft=2048, hop_length=512)\n",
    "    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)  #visualizing mel_spectrogram directly gives black image. So, coverting from power_to_db is required\n",
    "    mel_spectrograms[row[\"category\"]] = mel_spec\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=signal , sr=rate , n_mfcc=13, dct_type=3)\n",
    "    mfccs[row[\"category\"]] = mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.iloc[0][\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce some audio samples\n",
    "print(sample_df.iloc[0][\"category\"])\n",
    "ipd.Audio(DATA_PATH + sample_df.iloc[0][\"filename\"])\n",
    "print(sample_df.iloc[1][\"category\"])\n",
    "ipd.Audio(DATA_PATH + sample_df.iloc[1][\"filename\"])\n",
    "print(sample_df.iloc[2][\"category\"])\n",
    "ipd.Audio(DATA_PATH + sample_df.iloc[2][\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_signal_seaborn(signal):\n",
    "    \"\"\"\n",
    "    this function will take the signal dictionary and plot the signals using seaborn\n",
    "    \"\"\"\n",
    "    sns.set(style='whitegrid')\n",
    "    fig , axes = plt.subplots(nrows=2 , ncols=5 , sharex =False ,sharey=True,figsize=(20,5))\n",
    "    fig.suptitle('Time series',size=15)\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(signals.keys())[i])\n",
    "            sns.lineplot(data=list(signals.values())[i], ax=axes[x,y])\n",
    "            axes[x,y].get_xaxis().set_visible(False)\n",
    "            axes[x,y].get_yaxis().set_visible(False)\n",
    "            i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal_seaborn(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_feature(mfccs, cmap=None):\n",
    "    \"\"\"\n",
    "    this function will take the mfcc/mel_spectrogram dictionary and plot the signals\n",
    "    \"\"\"\n",
    "    fig ,axes= plt.subplots(nrows=2 , ncols=5 , sharex=False, sharey=True , figsize=(40,10))\n",
    "    fig.suptitle('mel')\n",
    "    i=0\n",
    "    for x in range(2):\n",
    "        for y in range(5):\n",
    "            axes[x,y].set_title(list(mfccs.keys())[i])\n",
    "            axes[x,y].imshow(list(mfccs.values())[i], cmap=cmap,interpolation='nearest')\n",
    "            # axes[x,y].get_xaxis().set_visible(False)\n",
    "            # axes[x,y].get_yaxis().set_visible(False)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_feature(mel_spectrograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_sel, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data, scale=0.05):\n",
    "    noise = np.random.normal(0, scale, len(data))\n",
    "    audio_noisy = data + noise\n",
    "    return audio_noisy\n",
    "    \n",
    "def pitch_shifting(data, sr=16000):\n",
    "    sr  = sr\n",
    "    bins_per_octave = 12\n",
    "    pitch_pm = 2\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
    "    data = librosa.effects.pitch_shift(data.astype('float64'),  sr=sr, n_steps=pitch_change, \n",
    "                                          bins_per_octave=bins_per_octave)\n",
    "    return data\n",
    "\n",
    "def random_shift(data):\n",
    "    timeshift_fac = 0.2 *2*(np.random.uniform()-0.5)  # up to 20% of length\n",
    "    start = int(data.shape[0] * timeshift_fac)\n",
    "    if (start > 0):\n",
    "        data = np.pad(data,(start,0),mode='constant')[0:data.shape[0]]\n",
    "    else:\n",
    "        data = np.pad(data,(0,-start),mode='constant')[0:data.shape[0]]\n",
    "    return data\n",
    "\n",
    "def volume_scaling(data):\n",
    "    dyn_change = np.random.uniform(low=1.5,high=2.5)\n",
    "    data = data * dyn_change\n",
    "    return data\n",
    "    \n",
    "def time_stretching(data, rate=1.5):\n",
    "    input_length = len(data)\n",
    "    streching = data.copy()\n",
    "    streching = librosa.effects.time_stretch(streching, rate=rate)\n",
    "    \n",
    "    if len(streching) > input_length:\n",
    "        streching = streching[:input_length]\n",
    "    else:\n",
    "        streching = np.pad(streching, (0, max(0, input_length - len(streching))), \"constant\")\n",
    "    return streching\n",
    "\n",
    "def audio_augmentation(file, aug):\n",
    "    directory = 'ESC-50-augmented-data/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    aug = np.array(aug,dtype='float32').reshape(-1,1)\n",
    "    sf.write(directory+'/'+ file, aug, 16000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "row = df_sel.iloc[10]\n",
    "\n",
    "file_name = row[\"filename\"]\n",
    "print(row[\"category\"])\n",
    "signal , sr = librosa.load(DATA_PATH+file_name)\n",
    "print(\"original\")\n",
    "ipd.Audio(signal, rate=sr)\n",
    "\n",
    "noised = add_noise(signal, 0.005)\n",
    "print(\"noised\")\n",
    "ipd.Audio(noised, rate=sr) \n",
    "\n",
    "shifted = pitch_shifting(signal)\n",
    "\n",
    "print(\"pitch shifted\")\n",
    "ipd.Audio(shifted, rate=sr)\n",
    "\n",
    "print(\"random shifted\")\n",
    "r_shifted = random_shift(signal)\n",
    "ipd.Audio(r_shifted, rate=sr)\n",
    "\n",
    "print(\"volume scaled\")\n",
    "vol_scaled = volume_scaling(signal)\n",
    "ipd.Audio(vol_scaled, rate=sr)\n",
    "\n",
    "print(\"time stretching\")\n",
    "time_stretched = time_stretching(signal)\n",
    "len(time_stretched)\n",
    "ipd.Audio(time_stretched, rate=sr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_df(df):\n",
    "\n",
    "    totals = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        df_temp = pd.DataFrame()\n",
    "        signal , sr = librosa.load(DATA_PATH+row[\"filename\"])\n",
    "        aug_signals = {\n",
    "            \"original\": signal,\n",
    "            \"noised\": add_noise(signal, 0.005),\n",
    "            \"pitch_shift\": pitch_shifting(signal),\n",
    "            \"random_shifted\": random_shift(signal),\n",
    "            \"vol_scaled\": volume_scaling(signal),\n",
    "            \"time_stretched\": time_stretching(signal)\n",
    "        }\n",
    "\n",
    "        df_temp = df_temp._append([row]*len(aug_signals),ignore_index=True)\n",
    "\n",
    "        # signal_arrays = []\n",
    "        # signal_types = []\n",
    "        # for i, (key, val) in enumerate(aug_signals.items()):\n",
    "        #     signal_arrays.append(val)\n",
    "        #     signal_types.append(key)\n",
    "\n",
    "        df_temp[\"signal\"] = aug_signals.values()\n",
    "        df_temp[\"type\"] = aug_signals.keys()\n",
    "        \n",
    "        totals.append(df_temp)\n",
    "            \n",
    "    return pd.concat(totals)\n",
    "\n",
    "def load_signals(df):\n",
    "    df[\"signal\"] = df[\"filename\"].apply(lambda x: librosa.load(DATA_PATH+x)[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_aug = augment_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_signals(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_aug.groupby(\"fold\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each audio sample, create three additional random samples to augment data\n",
    "# # each audio sampel has typically 5 seconds. \n",
    "\n",
    "# # TODO: experiment with different lengths of the random samples or no random samples at all and see the performance. \n",
    "\n",
    "# X , y = [] , []\n",
    "# for i, data in tqdm(df_sel.iloc[0:2].iterrows()):\n",
    "#   print(data[\"filename\"])\n",
    "#   sig , sr = librosa.load(DATA_PATH+data[\"filename\"])\n",
    "#   for i in range(3):\n",
    "#     n = np.random.randint(0, len(sig)-(sr*2)) # chose a random number between 0 and about 3/5 of the signal length or 3 seconds as signals are 5 seconds long.\n",
    "#     sig_ = sig[n : int(n+(sr*2))] # take a 2 seconds long chunk of the signal starting from the n random position. \n",
    "#     mfcc_ = librosa.feature.mfcc(y=sig_ , sr=sr, n_mfcc=13)\n",
    "#     X.append(mfcc_)\n",
    "#     y.append(data[\"target\"])\n",
    "\n",
    "# # convert list to numpy array\n",
    "# X = np.array(X) \n",
    "# y = np.array(y)\n",
    "\n",
    "# #one-hot encoding the target\n",
    "# y = tf.keras.utils.to_categorical(y , num_classes=10)\n",
    "\n",
    "# # our tensorflow model takes input as (no_of_sample , height , width , channel).\n",
    "# # here X has dimension (no_of_sample , height , width).\n",
    "# # So, the below code will reshape it to (no_of_sample , height , width , 1).\n",
    "# X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tf(df):\n",
    "    sr = 22050\n",
    "    X , y = [] , []\n",
    "    for i, data in tqdm(df.iterrows()):\n",
    "        mfcc_ = librosa.feature.mfcc(y=data[\"signal\"], sr=sr, n_mfcc=13)\n",
    "        X.append(mfcc_)\n",
    "        y.append(data[\"target\"])\n",
    "\n",
    "    # convert list to numpy array\n",
    "    X = np.array(X) \n",
    "    y = np.array(y)\n",
    "\n",
    "    #one-hot encoding the target\n",
    "    y = tf.keras.utils.to_categorical(y , num_classes=10)\n",
    "\n",
    "    # our tensorflow model takes input as (no_of_sample , height , width , channel).\n",
    "    # here X has dimension (no_of_sample , height , width).\n",
    "    # So, the below code will reshape it to (no_of_sample , height , width , 1).\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train = df_to_tf(df_train_aug)\n",
    "X_val, y_val = df_to_tf(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "INPUTSHAPE = (13,216,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"logs\"\n",
    "CPKT = \"cpkt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this callback is used to prevent overfitting.\n",
    "callback_1 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.01, patience=60, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "#this checkpoint saves the best weights of model at every epoch\n",
    "callback_2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n",
    ")\n",
    "\n",
    "#this is for tensorboard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "                          layers.Conv2D(16 , (3,3),activation = 'relu',padding='valid', input_shape = INPUTSHAPE),\n",
    "                          BatchNormalization(),\n",
    "                          layers.Conv2D(64, (3,3), activation='relu',padding='valid'),\n",
    "                          BatchNormalization(),\n",
    "                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n",
    "                          BatchNormalization(),\n",
    "                          layers.GlobalAveragePooling2D(),\n",
    "                          Dropout(0.5),\n",
    "                          layers.Dense(32 , activation = 'relu'),\n",
    "                          Dropout(0.5),\n",
    "                          layers.Dense(10 , activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented = augment_df(df_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate single fold\n",
    "df_train_fold = df_augmented[df_augmented[\"fold\"] !=1] \n",
    "df_val_fold = df_augmented[(df_augmented[\"fold\"] == 1) & (df_augmented[\"type\"] == \"original\")] # Select only the original data for the validation fold.\n",
    "\n",
    "X_train, y_train =  df_to_tf(df_train_fold)\n",
    "X_val, y_val = df_to_tf(df_val_fold)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train,y_train,\n",
    "        validation_data=(X_val,y_val),\n",
    "        epochs=150,\n",
    "        callbacks = [callback_1 , callback_2 , tensorboard_callback])\n",
    "\n",
    "_, accuracy = model.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dict = {value: key for key, value in class_dict.items()}\n",
    "# Assuming `sample` is your single sample\n",
    "row = df_val_fold.sample(1)\n",
    "\n",
    "ipd.Audio(row[\"signal\"].iloc[0], rate=sr)\n",
    "print(row[\"target\"])\n",
    "xp, yp = df_to_tf(row)\n",
    "prediction = model.predict(xp)  # Get the model's prediction\n",
    "\n",
    "# # The prediction is an array of probabilities for each class. \n",
    "# # To get the class with the highest probability, you can use argmax\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "print(f\"The predicted class is {inverted_dict[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# df_sel_signals = load_signals(df_sel)\n",
    "# df_sel_signals[\"type\"] = \"original\"\n",
    "df_augmented = augment_df(df_sel)\n",
    "\n",
    "# 5 folds\n",
    "\n",
    "n_folds = 2\n",
    "fold_accuracy = []\n",
    "\n",
    "for i in range(1, n_folds + 1):\n",
    "\n",
    "    # split folds\n",
    "    df_train_fold = df_augmented[df_augmented[\"fold\"] !=i]\n",
    "    df_val_fold = df_augmented[(df_augmented[\"fold\"] == i) & (df_augmented[\"type\"] == \"original\")] # Select only the original data for the validation fold.\n",
    "\n",
    "    # convert to tensors\n",
    "    X_train, y_train =  df_to_tf(df_train_fold)\n",
    "    X_val, y_val = df_to_tf(df_val_fold)\n",
    "\n",
    "    model = create_model()\n",
    "    model.fit(X_train,y_train,\n",
    "            validation_data=(X_val,y_val),\n",
    "            epochs=120,\n",
    "            callbacks = [callback_1 , callback_2 , tensorboard_callback])\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    fold_accuracy.append(accuracy)\n",
    "\n",
    "print(f\"Average Accuracy: {np.mean(fold_accuracy) * 100}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having fined tuned the model, now split data in training and validation\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "df_train, df_val = train_test_split(df_sel)\n",
    "\n",
    "# for validation use only original data, exclude augmented. \n",
    "df_train = augment_df(df_train)\n",
    "df_val = load_signals(df_val)\n",
    "\n",
    "print(\"training size\", df_train.shape)\n",
    "print(\"validation size\", df_val.shape)\n",
    "\n",
    "# convert to tensors\n",
    "X_train, y_train =  df_to_tf(df_train)\n",
    "X_val, y_val = df_to_tf(df_val)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(X_train,y_train,\n",
    "        validation_data=(X_val,y_val),\n",
    "        epochs=90,\n",
    "        callbacks = [callback_1 , callback_2 , tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

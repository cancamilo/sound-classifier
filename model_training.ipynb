{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to train the sound classification model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CSV_FILE_PATH = \"data/esc50.csv\"  # path of csv file\n",
    "DATA_PATH = \"data/audio/44100/\" # path to folder containing audio files\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "\n",
    "# from the full data set with 40 different classes, select the classes you want to filter. \n",
    "\n",
    "class_selection = [\n",
    "    \"thunderstorm\",\n",
    "    \"rain\",\n",
    "    \"sea_weaves\",\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"chirping_birds\",    \n",
    "    \"breathing\",\n",
    "    \"keyboard_typing\",\n",
    "    \"coughing\",\n",
    "    \"drinking_sipping\",\n",
    "    \"car_horn\"\n",
    "]\n",
    "\n",
    "df_sel = df[df[\"category\"].isin(class_selection)]\n",
    "\n",
    "# Map each category to a new target column\n",
    "classes = df_sel['category'].unique()\n",
    "class_dict = {i:x for x,i in enumerate(classes)}\n",
    "df_sel.loc[:, 'target'] = df_sel['category'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data augmentation functions\n",
    "\n",
    "def add_noise(data, scale=0.05):\n",
    "    noise = np.random.normal(0, scale, len(data))\n",
    "    audio_noisy = data + noise\n",
    "    return audio_noisy\n",
    "    \n",
    "def pitch_shifting(data, sr=16000):\n",
    "    sr  = sr\n",
    "    bins_per_octave = 12\n",
    "    pitch_pm = 2\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
    "    data = librosa.effects.pitch_shift(data.astype('float64'),  sr=sr, n_steps=pitch_change, \n",
    "                                          bins_per_octave=bins_per_octave)\n",
    "    return data\n",
    "\n",
    "def random_shift(data):\n",
    "    timeshift_fac = 0.2 *2*(np.random.uniform()-0.5)  # up to 20% of length\n",
    "    start = int(data.shape[0] * timeshift_fac)\n",
    "    if (start > 0):\n",
    "        data = np.pad(data,(start,0),mode='constant')[0:data.shape[0]]\n",
    "    else:\n",
    "        data = np.pad(data,(0,-start),mode='constant')[0:data.shape[0]]\n",
    "    return data\n",
    "\n",
    "def volume_scaling(data):\n",
    "    dyn_change = np.random.uniform(low=1.5,high=2.5)\n",
    "    data = data * dyn_change\n",
    "    return data\n",
    "    \n",
    "def time_stretching(data, rate=1.5):\n",
    "    input_length = len(data)\n",
    "    streching = data.copy()\n",
    "    streching = librosa.effects.time_stretch(streching, rate=rate)\n",
    "    \n",
    "    if len(streching) > input_length:\n",
    "        streching = streching[:input_length]\n",
    "    else:\n",
    "        streching = np.pad(streching, (0, max(0, input_length - len(streching))), \"constant\")\n",
    "    return streching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data peparing helper functions\n",
    "\n",
    "def augment_df(df):\n",
    "    \"\"\"\n",
    "    Apply variouys augmentation strategies the signals provided in the df\n",
    "    \"\"\"\n",
    "    totals = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        df_temp = pd.DataFrame()\n",
    "        signal , sr = librosa.load(DATA_PATH+row[\"filename\"])\n",
    "        aug_signals = {\n",
    "            \"original\": signal,\n",
    "            \"noised\": add_noise(signal, 0.005),\n",
    "            \"pitch_shift\": pitch_shifting(signal),\n",
    "            \"random_shifted\": random_shift(signal),\n",
    "            \"vol_scaled\": volume_scaling(signal),\n",
    "            \"time_stretched\": time_stretching(signal)\n",
    "        }\n",
    "\n",
    "        df_temp = df_temp._append([row]*len(aug_signals),ignore_index=True)\n",
    "\n",
    "        df_temp[\"signal\"] = aug_signals.values()\n",
    "        df_temp[\"type\"] = aug_signals.keys()\n",
    "        \n",
    "        totals.append(df_temp)\n",
    "            \n",
    "    return pd.concat(totals)\n",
    "\n",
    "def load_signals(df):\n",
    "    \"\"\"\n",
    "    Given a df with references to audio files, load each of the file to a numpy array \n",
    "    and returned a new dataframe with the loaded signals\n",
    "    \"\"\"\n",
    "    df[\"signal\"] = df[\"filename\"].apply(lambda x: librosa.load(DATA_PATH+x)[0])\n",
    "    return df\n",
    "\n",
    "def df_to_tf(df):\n",
    "    \"\"\"\n",
    "    Given a dataframe with audio signals as numpy arrays, apply the mfcc transformation and categorize the label classes.\n",
    "    and reshape into X and y for the CNN model. \n",
    "    \"\"\"\n",
    "    sr = 22050\n",
    "    X , y = [] , []\n",
    "    for _, data in df.iterrows():\n",
    "        mfcc_ = librosa.feature.mfcc(y=data[\"signal\"], sr=sr, n_mfcc=13)\n",
    "        X.append(mfcc_)\n",
    "        y.append(data[\"target\"])\n",
    "\n",
    "    # convert list to numpy array\n",
    "    X = np.array(X) \n",
    "    y = np.array(y)\n",
    "\n",
    "    #one-hot encoding the target\n",
    "    y = tf.keras.utils.to_categorical(y , num_classes=10)\n",
    "\n",
    "    # our tensorflow model takes input as (no_of_sample , height , width , channel).\n",
    "    # here X has dimension (no_of_sample , height , width).\n",
    "    # So, the below code will reshape it to (no_of_sample , height , width , 1).\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Define the CNN architecture\n",
    "def create_model():\n",
    "    INPUTSHAPE = (13,216,1)\n",
    "    model = models.Sequential([\n",
    "                          layers.Conv2D(16 , (3,3),activation = 'relu',padding='valid', input_shape = INPUTSHAPE),\n",
    "                          BatchNormalization(),\n",
    "                          layers.Conv2D(64, (3,3), activation='relu',padding='valid'),\n",
    "                          BatchNormalization(),\n",
    "                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n",
    "                          BatchNormalization(),\n",
    "                          layers.GlobalAveragePooling2D(),\n",
    "                          Dropout(0.5),\n",
    "                          layers.Dense(32 , activation = 'relu'),\n",
    "                          Dropout(0.5),\n",
    "                          layers.Dense(10 , activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_sel, test_size=0.2, random_state=2023)\n",
    "\n",
    "# augment only the training data\n",
    "df_train_aug = augment_df(df_train)\n",
    "df_val = load_signals(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_to_tf(df_train_aug)\n",
    "X_val, y_val = df_to_tf(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:55:13.650639: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-22 16:55:13.652235: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:55:13.963479: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-01-22 16:55:14.275023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/60 [===========================>..] - ETA: 0s - loss: 2.1940 - acc: 0.2018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:55:16.120337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 2s 26ms/step - loss: 2.1891 - acc: 0.2052 - val_loss: 2.1304 - val_acc: 0.2500\n",
      "Epoch 2/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.9278 - acc: 0.3187 - val_loss: 1.9777 - val_acc: 0.3500\n",
      "Epoch 3/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.8093 - acc: 0.3760 - val_loss: 1.8180 - val_acc: 0.3875\n",
      "Epoch 4/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6744 - acc: 0.4266 - val_loss: 1.7161 - val_acc: 0.4250\n",
      "Epoch 5/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.5335 - acc: 0.4724 - val_loss: 1.3962 - val_acc: 0.6625\n",
      "Epoch 6/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.4716 - acc: 0.4932 - val_loss: 1.2712 - val_acc: 0.5875\n",
      "Epoch 7/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.3654 - acc: 0.5198 - val_loss: 1.2685 - val_acc: 0.5500\n",
      "Epoch 8/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.2794 - acc: 0.5568 - val_loss: 1.2183 - val_acc: 0.5875\n",
      "Epoch 9/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.2291 - acc: 0.5818 - val_loss: 0.9926 - val_acc: 0.6750\n",
      "Epoch 10/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.1686 - acc: 0.5813 - val_loss: 0.9280 - val_acc: 0.7500\n",
      "Epoch 11/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.1084 - acc: 0.6130 - val_loss: 0.8814 - val_acc: 0.7250\n",
      "Epoch 12/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.0811 - acc: 0.6187 - val_loss: 0.9324 - val_acc: 0.6875\n",
      "Epoch 13/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.0210 - acc: 0.6562 - val_loss: 0.8308 - val_acc: 0.7500\n",
      "Epoch 14/90\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.9631 - acc: 0.6672 - val_loss: 0.8884 - val_acc: 0.7125\n",
      "Epoch 15/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.9352 - acc: 0.6703 - val_loss: 0.9985 - val_acc: 0.6750\n",
      "Epoch 16/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8929 - acc: 0.6922 - val_loss: 0.7310 - val_acc: 0.8000\n",
      "Epoch 17/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.9095 - acc: 0.6901 - val_loss: 0.9245 - val_acc: 0.6750\n",
      "Epoch 18/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8582 - acc: 0.6984 - val_loss: 0.6953 - val_acc: 0.8000\n",
      "Epoch 19/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8025 - acc: 0.7328 - val_loss: 0.7119 - val_acc: 0.7750\n",
      "Epoch 20/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7830 - acc: 0.7302 - val_loss: 0.8450 - val_acc: 0.7250\n",
      "Epoch 21/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7567 - acc: 0.7354 - val_loss: 0.8464 - val_acc: 0.7000\n",
      "Epoch 22/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7506 - acc: 0.7448 - val_loss: 0.7507 - val_acc: 0.7125\n",
      "Epoch 23/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7233 - acc: 0.7536 - val_loss: 0.7227 - val_acc: 0.7375\n",
      "Epoch 24/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7180 - acc: 0.7526 - val_loss: 0.7224 - val_acc: 0.7500\n",
      "Epoch 25/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6657 - acc: 0.7651 - val_loss: 0.5953 - val_acc: 0.8250\n",
      "Epoch 26/90\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.6874 - acc: 0.7651 - val_loss: 0.6587 - val_acc: 0.7625\n",
      "Epoch 27/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6149 - acc: 0.7943 - val_loss: 0.6503 - val_acc: 0.7625\n",
      "Epoch 28/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6366 - acc: 0.7906 - val_loss: 0.7050 - val_acc: 0.7500\n",
      "Epoch 29/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6223 - acc: 0.7870 - val_loss: 0.6078 - val_acc: 0.8125\n",
      "Epoch 30/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5694 - acc: 0.8135 - val_loss: 0.5940 - val_acc: 0.8250\n",
      "Epoch 31/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5920 - acc: 0.8010 - val_loss: 0.6248 - val_acc: 0.7875\n",
      "Epoch 32/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5857 - acc: 0.8099 - val_loss: 0.7397 - val_acc: 0.7500\n",
      "Epoch 33/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.6238 - acc: 0.7917 - val_loss: 0.6113 - val_acc: 0.8000\n",
      "Epoch 34/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5609 - acc: 0.8130 - val_loss: 0.6476 - val_acc: 0.7875\n",
      "Epoch 35/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5483 - acc: 0.8167 - val_loss: 0.6390 - val_acc: 0.7875\n",
      "Epoch 36/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5174 - acc: 0.8354 - val_loss: 0.7941 - val_acc: 0.7875\n",
      "Epoch 37/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5171 - acc: 0.8349 - val_loss: 0.5681 - val_acc: 0.8125\n",
      "Epoch 38/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4725 - acc: 0.8469 - val_loss: 0.6462 - val_acc: 0.8125\n",
      "Epoch 39/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4860 - acc: 0.8333 - val_loss: 0.7196 - val_acc: 0.7875\n",
      "Epoch 40/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5050 - acc: 0.8224 - val_loss: 0.7003 - val_acc: 0.7750\n",
      "Epoch 41/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4325 - acc: 0.8594 - val_loss: 0.6241 - val_acc: 0.8125\n",
      "Epoch 42/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4569 - acc: 0.8568 - val_loss: 0.7466 - val_acc: 0.8000\n",
      "Epoch 43/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4517 - acc: 0.8432 - val_loss: 0.6963 - val_acc: 0.7625\n",
      "Epoch 44/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4479 - acc: 0.8495 - val_loss: 0.5559 - val_acc: 0.8375\n",
      "Epoch 45/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4756 - acc: 0.8484 - val_loss: 0.6434 - val_acc: 0.8000\n",
      "Epoch 46/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4418 - acc: 0.8568 - val_loss: 0.5488 - val_acc: 0.8375\n",
      "Epoch 47/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4095 - acc: 0.8635 - val_loss: 0.7244 - val_acc: 0.7500\n",
      "Epoch 48/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3974 - acc: 0.8734 - val_loss: 0.5541 - val_acc: 0.8250\n",
      "Epoch 49/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4484 - acc: 0.8526 - val_loss: 0.7253 - val_acc: 0.7750\n",
      "Epoch 50/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.4072 - acc: 0.8682 - val_loss: 0.4827 - val_acc: 0.8375\n",
      "Epoch 51/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.4164 - acc: 0.8609 - val_loss: 0.5866 - val_acc: 0.8125\n",
      "Epoch 52/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3883 - acc: 0.8776 - val_loss: 0.7078 - val_acc: 0.7750\n",
      "Epoch 53/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3893 - acc: 0.8698 - val_loss: 0.6420 - val_acc: 0.7750\n",
      "Epoch 54/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3693 - acc: 0.8818 - val_loss: 0.5233 - val_acc: 0.8250\n",
      "Epoch 55/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3481 - acc: 0.8891 - val_loss: 0.5183 - val_acc: 0.8250\n",
      "Epoch 56/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3551 - acc: 0.8891 - val_loss: 0.6099 - val_acc: 0.8000\n",
      "Epoch 57/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3843 - acc: 0.8693 - val_loss: 0.5142 - val_acc: 0.8250\n",
      "Epoch 58/90\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.3511 - acc: 0.8896 - val_loss: 0.4507 - val_acc: 0.8625\n",
      "Epoch 59/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3619 - acc: 0.8818 - val_loss: 0.6177 - val_acc: 0.7750\n",
      "Epoch 60/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3318 - acc: 0.8932 - val_loss: 0.6695 - val_acc: 0.8125\n",
      "Epoch 61/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3430 - acc: 0.8792 - val_loss: 0.5690 - val_acc: 0.8500\n",
      "Epoch 62/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3569 - acc: 0.8875 - val_loss: 0.7775 - val_acc: 0.7500\n",
      "Epoch 63/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3352 - acc: 0.8906 - val_loss: 0.7998 - val_acc: 0.8000\n",
      "Epoch 64/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3567 - acc: 0.8766 - val_loss: 0.4871 - val_acc: 0.8375\n",
      "Epoch 65/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3133 - acc: 0.8953 - val_loss: 0.5457 - val_acc: 0.8375\n",
      "Epoch 66/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2984 - acc: 0.9068 - val_loss: 0.6200 - val_acc: 0.8625\n",
      "Epoch 67/90\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.3208 - acc: 0.8964 - val_loss: 0.6551 - val_acc: 0.8375\n",
      "Epoch 68/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3310 - acc: 0.8953 - val_loss: 0.7711 - val_acc: 0.7750\n",
      "Epoch 69/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.3435 - acc: 0.8995 - val_loss: 0.6001 - val_acc: 0.8000\n",
      "Epoch 70/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.3008 - acc: 0.8964 - val_loss: 0.5049 - val_acc: 0.8375\n",
      "Epoch 71/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2890 - acc: 0.9052 - val_loss: 0.4937 - val_acc: 0.8375\n",
      "Epoch 72/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2847 - acc: 0.9130 - val_loss: 0.5807 - val_acc: 0.8125\n",
      "Epoch 73/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2864 - acc: 0.9115 - val_loss: 0.4710 - val_acc: 0.8500\n",
      "Epoch 74/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2683 - acc: 0.9130 - val_loss: 0.6286 - val_acc: 0.8125\n",
      "Epoch 75/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2762 - acc: 0.9146 - val_loss: 0.6031 - val_acc: 0.7875\n",
      "Epoch 76/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2627 - acc: 0.9172 - val_loss: 0.4685 - val_acc: 0.8750\n",
      "Epoch 77/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2510 - acc: 0.9193 - val_loss: 0.5941 - val_acc: 0.8125\n",
      "Epoch 78/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2616 - acc: 0.9161 - val_loss: 0.5849 - val_acc: 0.8500\n",
      "Epoch 79/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2556 - acc: 0.9094 - val_loss: 0.5502 - val_acc: 0.8250\n",
      "Epoch 80/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2408 - acc: 0.9240 - val_loss: 0.5717 - val_acc: 0.8375\n",
      "Epoch 81/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2558 - acc: 0.9161 - val_loss: 0.4499 - val_acc: 0.8625\n",
      "Epoch 82/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2385 - acc: 0.9203 - val_loss: 0.7394 - val_acc: 0.8125\n",
      "Epoch 83/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2647 - acc: 0.9089 - val_loss: 0.4808 - val_acc: 0.8750\n",
      "Epoch 84/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2556 - acc: 0.9214 - val_loss: 0.6151 - val_acc: 0.8000\n",
      "Epoch 85/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2721 - acc: 0.9057 - val_loss: 0.4690 - val_acc: 0.8500\n",
      "Epoch 86/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2435 - acc: 0.9250 - val_loss: 0.5349 - val_acc: 0.8250\n",
      "Epoch 87/90\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.2541 - acc: 0.9229 - val_loss: 0.4648 - val_acc: 0.8750\n",
      "Epoch 88/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2515 - acc: 0.9161 - val_loss: 0.6447 - val_acc: 0.8250\n",
      "Epoch 89/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2573 - acc: 0.9156 - val_loss: 0.6491 - val_acc: 0.8000\n",
      "Epoch 90/90\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.2222 - acc: 0.9339 - val_loss: 0.5565 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29e507400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeling\n",
    "INPUTSHAPE = (13,216,1)\n",
    "LOGDIR = \"logs\"\n",
    "CPKT = \"cpkt/\"\n",
    "\n",
    "#this callback is used to prevent overfitting.\n",
    "callback_1 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.01, patience=60, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "#this checkpoint saves the best weights of model at every epoch\n",
    "callback_2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n",
    ")\n",
    "model = create_model()\n",
    "model.fit(X_train,y_train,\n",
    "        validation_data=(X_val,y_val),\n",
    "        epochs=90,\n",
    "        callbacks = [callback_1 , callback_2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
